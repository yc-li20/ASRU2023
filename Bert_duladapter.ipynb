{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch, transformers\n",
    "from transformers import BertForMaskedLM, BertTokenizer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (shared_parameters): ModuleDict()\n",
       "  (bert): BertModel(\n",
       "    (shared_parameters): ModuleDict()\n",
       "    (invertible_adapters): ModuleDict()\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (key): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict()\n",
       "              )\n",
       "              (value): Linear(\n",
       "                in_features=768, out_features=768, bias=True\n",
       "                (loras): ModuleDict(\n",
       "                  (lora_adapter1): LoRA()\n",
       "                  (lora_adapter2): LoRA()\n",
       "                )\n",
       "              )\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (prefix_tuning): PrefixTuningShim(\n",
       "                (prefix_gates): ModuleDict()\n",
       "                (pool): PrefixTuningPool(\n",
       "                  (prefix_tunings): ModuleDict()\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (adapters): ModuleDict()\n",
       "              (adapter_fusion_layer): ModuleDict()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(\n",
       "              in_features=768, out_features=3072, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(\n",
       "              in_features=3072, out_features=768, bias=True\n",
       "              (loras): ModuleDict()\n",
       "            )\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (adapters): ModuleDict()\n",
       "            (adapter_fusion_layer): ModuleDict()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prefix_tuning): PrefixTuningPool(\n",
       "      (prefix_tunings): ModuleDict()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 添加LoRA适配器\n",
    "from transformers.adapters import LoRAConfig\n",
    "\n",
    "config1 = LoRAConfig(r=8, alpha=16)\n",
    "config2 = LoRAConfig(r=8, alpha=16)\n",
    "model.add_adapter(\"lora_adapter1\", config=config1)\n",
    "model.add_adapter(\"lora_adapter2\", config=config2)\n",
    "model.set_active_adapters(\"lora_adapter1\")  # 设置适配器1为活动适配器\n",
    "model.train_adapter(\"lora_adapter1\", train_embeddings=True)\n",
    "model.set_active_adapters(\"lora_adapter2\")  # 设置适配器2为活动适配器\n",
    "model.train_adapter(\"lora_adapter2\", train_embeddings=True)\n",
    "\n",
    "# 将模型移动到设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🥶 Frozen layer 'bert.embeddings.word_embeddings.weight'\n",
      "🥶 Frozen layer 'bert.embeddings.position_embeddings.weight'\n",
      "🥶 Frozen layer 'bert.embeddings.token_type_embeddings.weight'\n",
      "🥶 Frozen layer 'bert.embeddings.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.embeddings.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.0.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.0.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.0.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.0.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.0.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.1.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.1.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.1.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.1.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.1.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.2.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.2.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.2.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.2.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.2.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.3.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.3.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.3.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.3.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.3.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.4.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.4.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.4.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.4.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.4.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.5.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.5.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.5.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.5.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.5.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.6.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.6.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.6.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.6.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.6.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.7.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.7.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.7.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.7.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.7.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.8.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.8.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.8.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.8.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.8.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.9.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.9.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.9.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.9.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.9.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.10.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.10.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.10.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.10.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.10.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.self.query.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.self.query.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.11.attention.self.query.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.11.attention.self.query.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.self.key.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.self.key.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.self.value.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.self.value.bias'\n",
      "🚀 Trainable layer 'bert.encoder.layer.11.attention.self.value.loras.lora_adapter1.lora_A'\n",
      "🚀 Trainable layer 'bert.encoder.layer.11.attention.self.value.loras.lora_adapter1.lora_B'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.attention.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.intermediate.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.intermediate.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.output.dense.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.output.dense.bias'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.output.LayerNorm.weight'\n",
      "🥶 Frozen layer 'bert.encoder.layer.11.output.LayerNorm.bias'\n",
      "🥶 Frozen layer 'cls.predictions.bias'\n",
      "🥶 Frozen layer 'cls.predictions.transform.dense.weight'\n",
      "🥶 Frozen layer 'cls.predictions.transform.dense.bias'\n",
      "🥶 Frozen layer 'cls.predictions.transform.LayerNorm.weight'\n",
      "🥶 Frozen layer 'cls.predictions.transform.LayerNorm.bias'\n",
      "Total frozen parameters: 109514298\n",
      "Total trainable parameters: 294912\n"
     ]
    }
   ],
   "source": [
    "# emb_params = 0\n",
    "# trainable_params = 0\n",
    "# frozen_params = 0\n",
    "# for name, param in model.named_parameters():\n",
    "#     if \"lora\" in name:\n",
    "#         param.requires_grad = True\n",
    "#         emb_params += param.numel()\n",
    "#     else:\n",
    "#         param.requires_grad = False\n",
    "\n",
    "#     if not param.requires_grad:\n",
    "#         print(f\"🥶 Frozen layer '{name}'\")\n",
    "#         frozen_params += param.numel()\n",
    "#     else:\n",
    "#         print(f\"🚀 Trainable layer '{name}'\")\n",
    "#         trainable_params += param.numel()\n",
    "\n",
    "# print(f\"Total frozen parameters: {frozen_params}\")\n",
    "# print(f\"Total trainable parameters: {trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#truth data\n",
    "path = '/afs/inf.ed.ac.uk/user/s20/s2057508/Documents/phdwork/ASRErrorCorrection/'\n",
    "data1_truth = path + '/05pt/ses1_truth.txt'\n",
    "data2_truth = path + '/05pt/ses2_truth.txt'\n",
    "data3_truth = path + '/05pt/ses3_truth.txt'\n",
    "data4_truth = path + '/05pt/ses4_truth.txt'\n",
    "data5_truth = path + '/05pt/ses5_truth.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans data\n",
    "path = '/afs/inf.ed.ac.uk/user/s20/s2057508/Documents/phdwork/ASRErrorCorrection/'\n",
    "data1_trans = path + '/05pt/ses1_trans.txt'\n",
    "data2_trans = path + '/05pt/ses2_trans.txt'\n",
    "data3_trans = path + '/05pt/ses3_trans.txt'\n",
    "data4_trans = path + '/05pt/ses4_trans.txt'\n",
    "data5_trans = path + '/05pt/ses5_trans.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data1_truth, 'r', encoding='utf-8') as f1:\n",
    "    lines1_truth = f1.readlines()\n",
    "with open(data2_truth, 'r', encoding='utf-8') as f2:\n",
    "    lines2_truth = f2.readlines()\n",
    "with open(data3_truth, 'r', encoding='utf-8') as f3:\n",
    "    lines3_truth = f3.readlines()\n",
    "with open(data4_truth, 'r', encoding='utf-8') as f4:\n",
    "    lines4_truth = f4.readlines()\n",
    "with open(data5_truth, 'r', encoding='utf-8') as f5:\n",
    "    lines5_truth = f5.readlines()\n",
    "\n",
    "with open(data1_trans, 'r', encoding='utf-8') as f6:\n",
    "    lines1_trans = f6.readlines()\n",
    "with open(data2_trans, 'r', encoding='utf-8') as f7:\n",
    "    lines2_trans = f7.readlines()\n",
    "with open(data3_trans, 'r', encoding='utf-8') as f8:\n",
    "    lines3_trans = f8.readlines()\n",
    "with open(data4_trans, 'r', encoding='utf-8') as f9:\n",
    "    lines4_trans = f9.readlines()\n",
    "with open(data5_trans, 'r', encoding='utf-8') as f10:\n",
    "    lines5_trans = f10.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "import random\n",
    "fold1_truth = lines2_truth + lines3_truth + lines4_truth + lines5_truth\n",
    "fold2_truth = lines1_truth + lines3_truth + lines4_truth + lines5_truth\n",
    "fold3_truth = lines1_truth + lines2_truth + lines4_truth + lines5_truth\n",
    "fold4_truth = lines1_truth + lines2_truth + lines3_truth + lines5_truth\n",
    "fold5_truth = lines1_truth + lines2_truth + lines3_truth + lines4_truth\n",
    "fold1_trans = lines2_trans + lines3_trans + lines4_trans + lines5_trans\n",
    "fold2_trans = lines1_trans + lines3_trans + lines4_trans + lines5_trans\n",
    "fold3_trans = lines1_trans + lines2_trans + lines4_trans + lines5_trans\n",
    "fold4_trans = lines1_trans + lines2_trans + lines3_trans + lines5_trans\n",
    "fold5_trans = lines1_trans + lines2_trans + lines3_trans + lines4_trans\n",
    "\n",
    "combined_fold1 = list(zip(fold1_truth, fold1_trans))\n",
    "combined_fold2 = list(zip(fold2_truth, fold2_trans))\n",
    "combined_fold3 = list(zip(fold3_truth, fold3_trans))\n",
    "combined_fold4 = list(zip(fold4_truth, fold4_trans))\n",
    "combined_fold5 = list(zip(fold5_truth, fold5_trans))\n",
    "random.shuffle(combined_fold1)\n",
    "random.shuffle(combined_fold2)\n",
    "random.shuffle(combined_fold3)\n",
    "random.shuffle(combined_fold4)\n",
    "random.shuffle(combined_fold5)\n",
    "# val data\n",
    "combined_lines1 = list(zip(lines1_truth, lines1_trans))\n",
    "combined_lines2 = list(zip(lines2_truth, lines2_trans))\n",
    "combined_lines3 = list(zip(lines3_truth, lines3_trans))\n",
    "combined_lines4 = list(zip(lines4_truth, lines4_trans))\n",
    "combined_lines5 = list(zip(lines5_truth, lines5_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = combined_fold1\n",
    "val_data = combined_lines1\n",
    "# train_data = combined_fold2\n",
    "# val_data = combined_lines2\n",
    "# train_data = combined_fold3\n",
    "# val_data = combined_lines3\n",
    "# train_data = combined_fold4\n",
    "# val_data = combined_lines4\n",
    "# train_data = combined_fold5\n",
    "# val_data = combined_lines5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_truth, train_trans = [tokenizer.encode(line_truth.strip(), add_special_tokens=True) for line_truth, _ in train_data], [tokenizer.encode(line_trans.strip(), add_special_tokens=True) for _, line_trans in train_data]\n",
    "train_truth, train_trans = [torch.tensor(b) for b in train_truth], [torch.tensor(b) for b in train_trans]\n",
    "train_truth, train_trans = torch.nn.utils.rnn.pad_sequence(train_truth, batch_first=True, padding_value=tokenizer.pad_token_id), torch.nn.utils.rnn.pad_sequence(train_trans, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "train_mask_truth, train_mask_trans = torch.ones_like(train_truth), torch.ones_like(train_trans)  # 创建与train_data形状相同的全1张量\n",
    "train_mask_truth[train_truth == tokenizer.pad_token_id] = 0  # 将填充token位置的mask设置为0\n",
    "train_mask_trans[train_trans == tokenizer.pad_token_id] = 0  # 将填充token位置的mask设置为0\n",
    "\n",
    "# 生成随机的mask\n",
    "mask_prob = 0.2  # 随机mask的概率\n",
    "mask_token_id = tokenizer.mask_token_id  # 获取mask token的ID\n",
    "rand_mask_truth = torch.rand(train_truth.shape) < mask_prob  # 随机生成掩码\n",
    "rand_mask_trans = torch.rand(train_trans.shape) < mask_prob  # 随机生成掩码\n",
    "\n",
    "train_truth[rand_mask_truth] = mask_token_id  # 将随机选中的token替换为mask token\n",
    "train_mask_truth[rand_mask_truth] = 0  # 将随机选中的token位置的mask设置为0\n",
    "train_trans[rand_mask_trans] = mask_token_id  # 将随机选中的token替换为mask token\n",
    "train_mask_trans[rand_mask_trans] = 0  # 将随机选中的token位置的mask设置为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_truth, val_trans = [tokenizer.encode(line_truth.strip(), add_special_tokens=True) for line_truth, _ in val_data], [tokenizer.encode(line_trans.strip(), add_special_tokens=True) for _, line_trans in val_data]\n",
    "val_truth, val_trans = [torch.tensor(b) for b in val_truth], [torch.tensor(b) for b in val_trans]\n",
    "val_truth, val_trans = torch.nn.utils.rnn.pad_sequence(val_truth, batch_first=True, padding_value=tokenizer.pad_token_id), torch.nn.utils.rnn.pad_sequence(val_trans, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "val_mask_truth, val_mask_trans = torch.ones_like(val_truth), torch.ones_like(val_trans)  # 创建与train_data形状相同的全1张量\n",
    "val_mask_truth[val_truth == tokenizer.pad_token_id] = 0  # 将填充token位置的mask设置为0\n",
    "val_mask_trans[val_trans == tokenizer.pad_token_id] = 0  # 将填充token位置的mask设置为0\n",
    "\n",
    "# 生成随机的mask\n",
    "mask_prob = 0.2  # 随机mask的概率\n",
    "mask_token_id = tokenizer.mask_token_id  # 获取mask token的ID\n",
    "rand_mask_truth = torch.rand(val_truth.shape) < mask_prob  # 随机生成掩码\n",
    "rand_mask_trans = torch.rand(val_trans.shape) < mask_prob  # 随机生成掩码\n",
    "\n",
    "val_truth[rand_mask_truth] = mask_token_id  # 将随机选中的token替换为mask token\n",
    "val_mask_truth[rand_mask_truth] = 0  # 将随机选中的token位置的mask设置为0\n",
    "val_trans[rand_mask_trans] = mask_token_id  # 将随机选中的token替换为mask token\n",
    "val_mask_trans[rand_mask_trans] = 0  # 将随机选中的token位置的mask设置为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "learning_rate = 1e-5\n",
    "adam_epsilon = 1e-8\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=adam_epsilon)\n",
    "best_val_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10: Average Loss = 2.2763, Truth Loss = 0.7810, Loss Trans = 0.8475, Time: 113.09 seconds\n",
      "Epoch 1 / 10: Average Validation Loss = 1.7888, Truth Loss = 1.1987, Trans Loss = 1.2712, Time: 112.58 seconds\n",
      "Epoch 2 / 10: Average Loss = 1.2554, Truth Loss = 0.1826, Loss Trans = 0.1897, Time: 112.58 seconds\n",
      "Epoch 2 / 10: Average Validation Loss = 0.4387, Truth Loss = 0.2770, Trans Loss = 0.2956, Time: 113.25 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Calculate loss only for non-padding tokens\u001b[39;00m\n\u001b[1;32m     30\u001b[0m active_loss_truth \u001b[38;5;241m=\u001b[39m batch_masks_truth\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 31\u001b[0m active_logits_truth \u001b[38;5;241m=\u001b[39m \u001b[43mlogits_truth\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mactive_loss_truth\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     32\u001b[0m active_labels_truth \u001b[38;5;241m=\u001b[39m labels_truth\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)[active_loss_truth]\n\u001b[1;32m     33\u001b[0m loss_truth \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(active_logits_truth, active_labels_truth)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 微调过程\n",
    "\n",
    "import time\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for i in range(0, len(train_truth), batch_size):\n",
    "        # 获取适配器1数据批次        \n",
    "        batch_inputs_truth = train_truth[i:i+batch_size].to(device)\n",
    "        batch_masks_truth = train_mask_truth[i:i+batch_size].to(device)\n",
    "        labels_truth = batch_inputs_truth.clone().detach()\n",
    "        labels_truth[labels_truth == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        # 获取适配器2数据批次        \n",
    "        batch_inputs_trans = train_trans[i:i+batch_size].to(device)\n",
    "        batch_masks_trans = train_mask_trans[i:i+batch_size].to(device)\n",
    "        labels_trans = batch_inputs_trans.clone().detach()\n",
    "        labels_trans[labels_trans == tokenizer.pad_token_id] = -100\n",
    "\n",
    "        # Forward pass\n",
    "        outputs_truth = model(input_ids=batch_inputs_truth, attention_mask=batch_masks_truth, labels=labels_truth)\n",
    "        logits_truth = outputs_truth.logits\n",
    "        outputs_trans = model(input_ids=batch_inputs_trans, attention_mask=batch_masks_trans, labels=labels_trans)\n",
    "        logits_trans = outputs_trans.logits\n",
    "\n",
    "        # Calculate loss only for non-padding tokens\n",
    "        active_loss_truth = batch_masks_truth.view(-1) != 0\n",
    "        active_logits_truth = logits_truth.view(-1, model.config.vocab_size)[active_loss_truth]\n",
    "        active_labels_truth = labels_truth.view(-1)[active_loss_truth]\n",
    "        loss_truth = F.cross_entropy(active_logits_truth, active_labels_truth)\n",
    "\n",
    "        active_loss_trans = batch_masks_trans.view(-1) != 0\n",
    "        active_logits_trans = logits_trans.view(-1, model.config.vocab_size)[active_loss_trans]\n",
    "        active_labels_trans = labels_trans.view(-1)[active_loss_trans]\n",
    "        loss_trans = F.cross_entropy(active_logits_trans, active_labels_trans)\n",
    "\n",
    "        loss = loss_truth + loss_trans\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    # Calculate average loss\n",
    "    avg_loss = total_loss / (len(train_data) // batch_size)\n",
    "    print(f\"Epoch {epoch+1} / {num_epochs}: Average Train Loss = {avg_loss:.4f}, Truth Loss = {loss_truth:.4f}, Trans Loss = {loss_trans:.4f}, Time: {epoch_time:.2f} seconds\")\n",
    "#     pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "#     print(pytorch_total_params)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(val_truth), batch_size):\n",
    "            # 获取适配器1数据批次        \n",
    "            batch_inputs_truth = val_truth[i:i+batch_size].to(device)\n",
    "            batch_masks_truth = val_mask_truth[i:i+batch_size].to(device)\n",
    "            labels_truth = batch_inputs_truth.clone().detach()\n",
    "            labels_truth[labels_truth == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            # 获取适配器2数据批次        \n",
    "            batch_inputs_trans = val_trans[i:i+batch_size].to(device)\n",
    "            batch_masks_trans = val_mask_trans[i:i+batch_size].to(device)\n",
    "            labels_trans = batch_inputs_trans.clone().detach()\n",
    "            labels_trans[labels_trans == tokenizer.pad_token_id] = -100\n",
    "\n",
    "            # Forward pass\n",
    "            outputs_truth = model(input_ids=batch_inputs_truth, attention_mask=batch_masks_truth, labels=labels_truth)\n",
    "            logits_truth = outputs_truth.logits\n",
    "            outputs_trans = model(input_ids=batch_inputs_trans, attention_mask=batch_masks_trans, labels=labels_trans)\n",
    "            logits_trans = outputs_trans.logits\n",
    "\n",
    "            # Calculate loss only for non-padding tokens\n",
    "            active_loss_truth = batch_masks_truth.view(-1) != 0\n",
    "            active_logits_truth = logits_truth.view(-1, model.config.vocab_size)[active_loss_truth]\n",
    "            active_labels_truth = labels_truth.view(-1)[active_loss_truth]\n",
    "            loss_truth = F.cross_entropy(active_logits_truth, active_labels_truth)\n",
    "\n",
    "            active_loss_trans = batch_masks_trans.view(-1) != 0\n",
    "            active_logits_trans = logits_trans.view(-1, model.config.vocab_size)[active_loss_trans]\n",
    "            active_labels_trans = labels_trans.view(-1)[active_loss_trans]\n",
    "            loss_trans = F.cross_entropy(active_logits_trans, active_labels_trans)\n",
    "\n",
    "            loss = loss_truth + loss_trans\n",
    "\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    # Calculate average validation loss\n",
    "    avg_val_loss = val_loss / (len(val_data) // batch_size)\n",
    "    end_time = time.time()\n",
    "    epoch_time = end_time - start_time\n",
    "    print(f\"Epoch {epoch+1} / {num_epochs}: Average Valid Loss = {avg_val_loss:.4f}, Truth Loss = {loss_truth:.4f}, Trans Loss = {loss_trans:.4f}, Time: {epoch_time:.2f} seconds\")\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    # Save the best model\n",
    "    if best_val_loss is None or avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), \"truth_model_fold5.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
